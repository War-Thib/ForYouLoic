{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OM - Assignment 4",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/War-Thib/ForYouLoic/blob/CleanPharmaCycle/OM_Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBsOSNPmab_o"
      },
      "source": [
        "# 0. Getting the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2IEglZZaVGc"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "dataset = \"assignment_4_dataset.csv\"\n",
        "\n",
        "saintx_data = pd.read_csv(dataset)\n",
        "\n",
        "saintx_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db9g30jmbhJY"
      },
      "source": [
        "# 1. Naive Forecast, MA3, MA5 and exponential smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kejq6OVwbgUJ"
      },
      "source": [
        "beers = ['Donker', 'Red', 'Tripel']\n",
        "\n",
        "def moving_average(series, order): \n",
        "    result = np.full(len(series) + 1, np.NaN)\n",
        "    for idx in range(order - 1, len(series) + 1 ):\n",
        "        result[idx] = np.mean(series[idx-order:idx])\n",
        "    return result\n",
        "\n",
        "def exponential_smoothing(series, alpha = 0.5):\n",
        "    result = np.full(len(series) + 1, np.NaN)\n",
        "    result[1] = series[0]\n",
        "    for idx in range(2, len(series) + 1):\n",
        "        result[idx] = alpha * series[idx - 1] + \\\n",
        "        (1 - alpha) * result[idx - 1]\n",
        "    return result   \n",
        "\n",
        "def double_exponential_smoothing(series, alpha, beta):\n",
        "  \n",
        "  forecast = np.full(len(series) + 1, np.NaN)\n",
        "  a = np.full(len(series)+1, np.NaN)  # a et b sont des étapes intermédiaires nécessaires au calcul des prévisions\n",
        "  b = np.full(len(series)+1, np.NaN)\n",
        "\n",
        "  a[0] = series[0]\n",
        "  a[1] = series[1]\n",
        "  b[1] = series[1] - series[0]\n",
        "\n",
        "  \n",
        "  for idx in range(2, len(series)):\n",
        "      forecast[idx] = a[idx - 1] + b[idx - 1]\n",
        "      a[idx] = alpha * series[idx] + (1 - alpha) * (a[idx - 1] + b[idx - 1])\n",
        "      b[idx] = beta * (a[idx] - a[idx - 1]) + (1 - beta) * b[idx - 1]\n",
        "  \n",
        "  forecast[-1] = a[-2] + b[-2]\n",
        "      \n",
        "  return forecast     \n",
        "\n",
        "\n",
        "for b in beers:\n",
        "  #naive forecast\n",
        "  saintx_data[\"Naive_forecast_\"+b] = saintx_data[b +\" Drunk\"].shift(1)\n",
        "  # moving average 3-5\n",
        "  saintx_data[b+\"_MA3_forecast\"] = moving_average(saintx_data[b + \" Drunk\"][:-1], 3)\n",
        "  saintx_data[b+\"_MA5_forecast\"] = moving_average(saintx_data[b + \" Drunk\"][:-1], 5)\n",
        "  # simple exponential smoothing\n",
        "  saintx_data[\"SES_\"+b] = exponential_smoothing(saintx_data[b +' Drunk'][:-1], 0.2)\n",
        "  # exponential smoothing with trend\n",
        "  saintx_data[\"DES_\" + b] = double_exponential_smoothing(saintx_data[b + \" Drunk\"][:-1], 0.5, 0.5)\n",
        "\n",
        "\n",
        "saintx_data = saintx_data.drop([0,1,2,3,4]) \n",
        "\n",
        "saintx_data = saintx_data.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# saintx_data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvzIIkDsRVvp"
      },
      "source": [
        "# 2. The best error measure (MSE) \n",
        "\n",
        "## Why ?\n",
        "Accoring to us, the best error measure in this case is the MSE. In this forecasting case, only the really big errors_donker will create dramatic situations (bankrupcy and anger). And the MSE, is giving more weight in the balance to important errors_donker. That's the reason why we'll choose the forecast model which scores best whith as error measure the MSE.\n",
        "\n",
        "## The best forecasting model according to the MSE ?\n",
        "\n",
        "The best forecasting model according to the MSE, is the Moving average order 5. With an error of 21390.49\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sokC0q4LSrNJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "65782220-1aa0-46b6-da57-c553a8791635"
      },
      "source": [
        "# let's calculate the MSE error for each model for each beer, pour le MSE j'ai besoin de l'erreur et de l'erreur au carré\n",
        "beers = ['Donker', 'Red', 'Tripel']\n",
        "squared = lambda x: x**2\n",
        "\n",
        "for b in beers:\n",
        "  # error + squared error for naive forecast\n",
        "  saintx_data['err_naive_'+b] = saintx_data[b+' Drunk'] - saintx_data['Naive_forecast_'+b]\n",
        "  saintx_data['squarred_err_naive_'+b] =  list(map(squared, saintx_data['err_naive_'+b]))\n",
        "\n",
        "  # error + squarred error for MA3-MA5\n",
        "  saintx_data['err_MA3_'+b] = saintx_data[b+' Drunk'] - saintx_data[b+'_MA3_forecast']\n",
        "  saintx_data['squarred_err_MA3_'+b] =  list(map(squared, saintx_data['err_MA3_'+b]))\n",
        "  saintx_data['err_MA5_'+b] = saintx_data[b+' Drunk'] - saintx_data[b+'_MA5_forecast']\n",
        "  saintx_data['squarred_err_MA5_'+b] =  list(map(squared, saintx_data['err_MA5_'+b]))\n",
        "\n",
        "  # error + squarred error for simple exponential smoothing\n",
        "  saintx_data['err_SES_'+b] = saintx_data[b+' Drunk'] - saintx_data['SES_'+b]\n",
        "  saintx_data['squarred_err_SES_'+b] =  list(map(squared, saintx_data['err_SES_'+b]))\n",
        "\n",
        "  # error + squarred error for double exponential smoothing\n",
        "  saintx_data['err_DES_'+b] = saintx_data[b+' Drunk'] -saintx_data['DES_'+b]\n",
        "  saintx_data['squarred_err_DES_'+b] =  list(map(squared, saintx_data['err_DES_'+b]))\n",
        "\n",
        "#il y a blindé de colones c'est abusé\n",
        "saintx_data['constante_pour_MSE'] = saintx_data['Donker Drunk']/saintx_data['Donker Drunk'] #va me permettre de générer une colone de constante afin que je fasse mon groupby là dessus, c'est très laid mais ça va marcher\n",
        "\n",
        "# on en vient aux choses sérieuse je dois ici calculer le MSE \n",
        "\n",
        "mse = saintx_data.groupby(\"constante_pour_MSE\").aggregate([np.sum, len])\n",
        "\n",
        "for b in beers:\n",
        "  mse['mse_naive_'+b] = mse['squarred_err_naive_'+b]['sum']/mse['squarred_err_naive_'+b]['len']\n",
        "  mse['mse_MA3_'+b] = mse['squarred_err_MA3_'+b]['sum']/mse['squarred_err_MA3_'+b]['len']\n",
        "  mse['mse_MA5_'+b] = mse['squarred_err_MA5_'+b]['sum']/mse['squarred_err_MA5_'+b]['len']\n",
        "  mse['mse_SES_'+b] = mse['squarred_err_SES_'+b]['sum']/mse['squarred_err_SES_'+b]['len']\n",
        "  mse['mse_DES_'+b] = mse['squarred_err_DES_'+b]['sum']/mse['squarred_err_DES_'+b]['len']\n",
        "\n",
        "# afin de choisir le meilleur modèle => faire la somme des mse \n",
        "\n",
        "mse['sum_mse_naive'] = mse['mse_naive_Donker'] + mse['mse_naive_Red'] + mse['mse_naive_Tripel']\n",
        "mse['sum_mse_MA3'] = mse['mse_MA3_Donker'] + mse['mse_MA3_Red'] + mse['mse_MA3_Tripel']\n",
        "mse['sum_mse_MA5'] = mse['mse_MA5_Donker'] + mse['mse_MA5_Red'] + mse['mse_MA5_Tripel']\n",
        "mse['sum_mse_SES'] = mse['mse_SES_Donker'] + mse['mse_SES_Red'] + mse['mse_SES_Tripel']\n",
        "mse['sum_mse_DES'] = mse['mse_DES_Donker'] + mse['mse_DES_Red'] + mse['mse_DES_Tripel']\n",
        "\n",
        "\n",
        "first_mse_model = mse[['sum_mse_naive','sum_mse_MA3', 'sum_mse_MA5','sum_mse_SES','sum_mse_DES']]\n",
        "first_mse_model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>sum_mse_naive</th>\n",
              "      <th>sum_mse_MA3</th>\n",
              "      <th>sum_mse_MA5</th>\n",
              "      <th>sum_mse_SES</th>\n",
              "      <th>sum_mse_DES</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>constante_pour_MSE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>29623.088889</td>\n",
              "      <td>22187.217284</td>\n",
              "      <td>21390.493333</td>\n",
              "      <td>22907.680336</td>\n",
              "      <td>28535.451443</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   sum_mse_naive   sum_mse_MA3  ...   sum_mse_SES   sum_mse_DES\n",
              "                                                ...                            \n",
              "constante_pour_MSE                              ...                            \n",
              "1.0                 29623.088889  22187.217284  ...  22907.680336  28535.451443\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbYoCzkx6RVO"
      },
      "source": [
        "#3. Some changes in the modelling of our forecasting model.\n",
        "\n",
        "The student association is giving us the information that if the forecast is too short in kegs, => all the sales losts are valuated at 2€.\n",
        "In the other hand, if the forecast is too large => all the beers remaining in the kegs are valuated at 1€.\n",
        "\n",
        "We need to implement thoses informations in the computation of our errors_donker. Just giving twice the weight to the negative errors_donker.\n",
        "\n",
        "\n",
        "En gros pour moi, il faut garder le MSE comme calcul d'erreur mais il faut ajouter 2fois plus de poids aux erreur négatives\n",
        "\n",
        "\n",
        "Ce que je propose c'est de faire c'est d'ajouter ces changements à notre base de donnée et doublant la valeur de l'erreur pour les erreurs négatives. En faisant cela on obtiendra des autres MSE et j'espère vraiment que ça sera un des trucs exponential qui gagnera \n",
        "\n",
        "\n",
        "Celui qui gagne c'est le forecast en MA3 avec une mse de 60151.93"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "EDv7Ucqw-fNV",
        "outputId": "e9bf32a2-689b-4a92-9243-23ad6599d801"
      },
      "source": [
        "# ici cette partie de code génère la colonne qui contient la nouvelle version de l'erreur qui est 2 fois plus importante si elle est négative\n",
        "\n",
        "for b in beers:\n",
        "  saintx_data['err_model_naive_'+b] = np.where(saintx_data['err_naive_'+b]>=0, saintx_data['err_naive_'+b]*2, saintx_data['err_naive_'+b]) \n",
        "  saintx_data['err_model_MA3_'+b] = np.where(saintx_data['err_MA3_'+b]>=0, saintx_data['err_MA3_'+b]*2, saintx_data['err_MA3_'+b])\n",
        "  saintx_data['err_model_MA5_'+b] = np.where(saintx_data['err_MA5_'+b]>=0, saintx_data['err_MA5_'+b]*2, saintx_data['err_MA5_'+b])\n",
        "  saintx_data['err_model_SES_'+b] = np.where(saintx_data['err_SES_'+b]>=0, saintx_data['err_SES_'+b]*2, saintx_data['err_SES_'+b])\n",
        "  saintx_data['err_model_DES_'+b] = np.where(saintx_data['err_DES_'+b]>=0, saintx_data['err_DES_'+b]*2, saintx_data['err_DES_'+b])\n",
        "\n",
        "\n",
        "  \n",
        "  #now let's create the squarred err of our new model_error\n",
        "  saintx_data['squarred_err_model_naive_'+b] =  list(map(squared, saintx_data['err_model_naive_'+b]))\n",
        "  saintx_data['squarred_err_model_MA3_'+b] =  list(map(squared, saintx_data['err_model_MA3_'+b]))\n",
        "  saintx_data['squarred_err_model_MA5_'+b] =  list(map(squared, saintx_data['err_model_MA5_'+b]))\n",
        "  saintx_data['squarred_err_model_SES_'+b] =  list(map(squared, saintx_data['err_model_SES_'+b]))\n",
        "  saintx_data['squarred_err_model_DES_'+b] =  list(map(squared, saintx_data['err_model_DES_'+b]))\n",
        "\n",
        "\n",
        "mse_model = saintx_data.groupby('constante_pour_MSE').aggregate([np.sum, len])\n",
        "mse_model = pd.DataFrame(mse_model)\n",
        "\n",
        "for b in beers:\n",
        "  mse_model['mse_model_naive_'+b] = mse_model['squarred_err_model_naive_'+b]['sum']/mse_model['squarred_err_model_naive_'+b]['len']\n",
        "  mse_model['mse_model_MA3_'+b] = mse_model['squarred_err_model_MA3_'+b]['sum']/mse_model['squarred_err_model_MA3_'+b]['len']\n",
        "  mse_model['mse_model_MA5_'+b] = mse_model['squarred_err_model_MA5_'+b]['sum']/mse_model['squarred_err_model_MA5_'+b]['len']\n",
        "  mse_model['mse_model_SES_'+b] = mse_model['squarred_err_model_SES_'+b]['sum']/mse_model['squarred_err_model_SES_'+b]['len']\n",
        "  mse_model['mse_model_DES_'+b] = mse_model['squarred_err_model_DES_'+b]['sum']/mse_model['squarred_err_model_DES_'+b]['len']\n",
        "\n",
        "\n",
        "#afin de choisir le meilleur modèle on fait la somme des 3\n",
        "mse_model['sum_mse_model_naive'] = mse_model['mse_model_naive_Donker'] + mse_model['mse_model_naive_Red'] + mse_model['mse_model_naive_Tripel']\n",
        "mse_model['sum_mse_model_MA3'] = mse_model['mse_model_MA3_Donker'] + mse_model['mse_model_MA3_Red'] + mse_model['mse_model_MA3_Tripel']\n",
        "mse_model['sum_mse_model_MA5'] = mse_model['mse_model_MA5_Donker'] + mse_model['mse_model_MA5_Red'] + mse_model['mse_model_MA5_Tripel']\n",
        "mse_model['sum_mse_model_SES'] = mse_model['mse_model_SES_Donker'] + mse_model['mse_model_SES_Red'] + mse_model['mse_model_SES_Tripel']\n",
        "mse_model['sum_mse_model_DES'] = mse_model['mse_model_DES_Donker'] + mse_model['mse_model_DES_Red'] + mse_model['mse_model_DES_Tripel']\n",
        "\n",
        "final_mse_model = mse_model[['sum_mse_model_naive','sum_mse_model_MA3','sum_mse_model_MA5','sum_mse_model_SES', 'sum_mse_model_DES' ]]\n",
        "final_mse_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>sum_mse_model_naive</th>\n",
              "      <th>sum_mse_model_MA3</th>\n",
              "      <th>sum_mse_model_MA5</th>\n",
              "      <th>sum_mse_model_SES</th>\n",
              "      <th>sum_mse_model_DES</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>constante_pour_MSE</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>74351.422222</td>\n",
              "      <td>60151.935802</td>\n",
              "      <td>61686.693333</td>\n",
              "      <td>72608.774531</td>\n",
              "      <td>67529.231449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   sum_mse_model_naive  ... sum_mse_model_DES\n",
              "                                        ...                  \n",
              "constante_pour_MSE                      ...                  \n",
              "1.0                       74351.422222  ...      67529.231449\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSuB5es-9ftR"
      },
      "source": [
        "#4. Which forecasting model ? (with the changes made in the part 3) With which parameters ?\n",
        "\n",
        "Even with the new error calculation, it still is the MA5 that outperform the other forecasting models.\n",
        "let's now see if we can optimise the parameter of the moving average.\n",
        "\n",
        "ici le problème c'est que je n'ai pas prit en compte les erreurs qui sont changées \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khrBqGx_caqz"
      },
      "source": [
        "## 4.1 Finding the best moving average order for the Donker Drunk\n",
        "\n",
        "\n",
        "The order that optimize the forecast is **4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8-1TfisSkdn"
      },
      "source": [
        "mas_donker = []\n",
        "\n",
        "saintx_data2 = pd.read_csv('assignment_4_dataset.csv')\n",
        "\n",
        "for order in range(1, 6):\n",
        "    forecast_donker = pd.DataFrame({\"Year\" : saintx_data2[\"Year\"],\n",
        "                            \"Order\" : order,\n",
        "                            \"Donker Drunk\" : saintx_data2[\"Donker Drunk\"]})\n",
        "    forecast_donker[\"Forecast Donker\"] = moving_average(saintx_data2[\"Donker Drunk\"], order)[:-1] #ici je dois comprend pourquoi est-ce que je ne dois pas mettre de [:-1]\n",
        "    mas_donker.append(forecast_donker)\n",
        "\n",
        "mas_donker = pd.concat(mas_donker, ignore_index = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIZ9UUnLcZez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "7b1778f7-b06d-41cc-edde-58f098029aec"
      },
      "source": [
        "errors_donker = mas_donker.copy()\n",
        "\n",
        "errors_donker = errors_donker.loc[errors_donker.Year >= 1975]\n",
        "errors_donker[\"Error\"] = errors_donker[\"Donker Drunk\"] - errors_donker['Forecast Donker']\n",
        "\n",
        "errors_donker[\"Model Error\"] = np.where(errors_donker[\"Error\"] >=0, errors_donker[\"Error\"]*2, errors_donker[\"Error\"])\n",
        "errors_donker[\"Model Squarred Error\"] = list(map(squared, errors_donker[\"Model Error\"]))\n",
        "\n",
        "mse_donker = errors_donker.groupby(\"Order\").aggregate([np.sum, len]).reset_index()\n",
        "\n",
        "mse_donker = pd.DataFrame({\"Order\" : mse_donker[\"Order\"],\n",
        "                    \"MSE\" : mse_donker[\"Model Squarred Error\"][\"sum\"] / mse_donker[\"Model Squarred Error\"][\"len\"]})\n",
        "\n",
        "mse_donker"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>36536.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>30320.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>29194.271605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>28161.644444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>30180.723556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Order           MSE\n",
              "0      1  36536.533333\n",
              "1      2  30320.083333\n",
              "2      3  29194.271605\n",
              "3      4  28161.644444\n",
              "4      5  30180.723556"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3wTsJAPcx3c"
      },
      "source": [
        "## 4.2 Finding the best moving average order for the Red Drunk\n",
        "\n",
        "The order that optimize the forecast is **2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrTbBgzdC16"
      },
      "source": [
        "mas_red = []\n",
        "\n",
        "for order in range(1, 6): # ici voir si j'investigue vers plus loin que ordre 10 ou pas => car le truc qui optimise le plus le modèle c'est ordre 13\n",
        "    forecast_red = pd.DataFrame({\"Year\" : saintx_data2[\"Year\"],\n",
        "                            \"Order\" : order,\n",
        "                            \"Red Drunk\" : saintx_data2[\"Red Drunk\"]})\n",
        "    forecast_red[\"Forecast Red\"] = moving_average(saintx_data2[\"Red Drunk\"], order)[:-1] #ici je dois comprend pourquoi est-ce que je ne dois pas mettre de [:-1]\n",
        "    mas_red.append(forecast_red)\n",
        "\n",
        "mas_red = pd.concat(mas_red, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4LQ0PGMd1tY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "605361db-4d27-4938-b7f5-325815801dcd"
      },
      "source": [
        "errors_red = mas_red.copy()\n",
        "\n",
        "errors_red = errors_red.loc[ errors_red.Year >= 1975]\n",
        "\n",
        "errors_red[\"Error\"] = errors_red[\"Red Drunk\"] - errors_red['Forecast Red']\n",
        "\n",
        "errors_red[\"Model Error\"] = np.where(errors_red[\"Error\"] >=0, errors_red[\"Error\"]*2, errors_red[\"Error\"])\n",
        "errors_red[\"Model Squarred Error\"] = list(map(squared, errors_red[\"Model Error\"]))\n",
        "\n",
        "\n",
        "mse_red = errors_red.groupby(\"Order\").aggregate([np.sum, len]).reset_index()\n",
        "\n",
        "mse_red = pd.DataFrame({\"Order\" : mse_red[\"Order\"],\n",
        "                    \"MSE\" : mse_red[\"Model Squarred Error\"][\"sum\"] / mse_red[\"Model Squarred Error\"][\"len\"]})\n",
        "\n",
        "mse_red"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>24208.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>19414.450000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>19617.864198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>20748.759722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>21240.401778</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Order           MSE\n",
              "0      1  24208.666667\n",
              "1      2  19414.450000\n",
              "2      3  19617.864198\n",
              "3      4  20748.759722\n",
              "4      5  21240.401778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFs59fwyeN3_"
      },
      "source": [
        "## 4.3 Finding the best moving average order for the tripel red\n",
        "\n",
        "The order that optimize the forecast is **5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGaXknRaefJD"
      },
      "source": [
        "mas_tripel = []\n",
        "\n",
        "for order in range(1, 6):\n",
        "    forecast_tripel = pd.DataFrame({\"Year\" : saintx_data2[\"Year\"],\n",
        "                            \"Order\" : order,\n",
        "                            \"Tripel Drunk\" : saintx_data2[\"Tripel Drunk\"]})\n",
        "    forecast_tripel[\"Forecast Tripel\"] = moving_average(saintx_data2[\"Tripel Drunk\"], order)[:-1] #ici je dois comprend pourquoi est-ce que je ne dois pas mettre de [:-1]\n",
        "    mas_tripel.append(forecast_tripel)\n",
        "\n",
        "mas_tripel = pd.concat(mas_tripel, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUVNKl2rereW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "04f1e6e0-bd26-45c9-d88e-e59d3591dd2c"
      },
      "source": [
        "errors_tripel = mas_tripel.copy()\n",
        "\n",
        "errors_tripel = errors_tripel.loc[errors_tripel.Year >= 1975]\n",
        "\n",
        "errors_tripel[\"Error\"] = errors_tripel[\"Tripel Drunk\"] - errors_tripel['Forecast Tripel']\n",
        "errors_tripel[\"Model Error\"] = np.where(errors_tripel[\"Error\"] >=0, errors_tripel[\"Error\"]*2, errors_tripel[\"Error\"])\n",
        "errors_tripel[\"Model Squarred Error\"] = list(map(squared, errors_tripel[\"Model Error\"]))\n",
        "\n",
        "mse_tripel = errors_tripel.groupby(\"Order\").aggregate([np.sum, len]).reset_index()\n",
        "\n",
        "mse_tripel = pd.DataFrame({\"Order\" : mse_tripel[\"Order\"],\n",
        "                    \"MSE\" : mse_tripel[\"Model Squarred Error\"][\"sum\"] / mse_tripel[\"Model Squarred Error\"][\"len\"]})\n",
        "\n",
        "mse_tripel"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Order</th>\n",
              "      <th>MSE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>13606.222222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>13003.855556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>11339.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>10342.647222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>10265.568000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Order           MSE\n",
              "0      1  13606.222222\n",
              "1      2  13003.855556\n",
              "2      3  11339.800000\n",
              "3      4  10342.647222\n",
              "4      5  10265.568000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz24cBz6TN7-"
      },
      "source": [
        "#5 What is your best estimate of the number of kegs to buy in 2020? Why (explain how you came to this recommendation)?\n",
        "\n",
        "Our results from the question 3:\n",
        "\n",
        "*   Best forecasting method for Donker Drunk = MA4\n",
        "*   Best forecasting method for Red Drunk = MA2\n",
        "*   Best forecasting method for Tripel Drunk = MA5\n",
        "\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "It's also time to think in terms of kegs and not of beers ( 1 kegs = 80 beers) The only remaining think to calculate is for the optimization of kegs => knowing that one beer remaining in the kegs = 1€ loss but 1 sale loss = 2€. This think is important to calculate the exact number of kegs we need.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWKOE0pQBcP0",
        "outputId": "9ff62176-e4d8-4ca8-9c71-ea7890502282"
      },
      "source": [
        "int(moving_average(saintx_data2[\"Donker Drunk\"], 4)[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqI_LG1MBolj",
        "outputId": "5bf029b2-8a5b-4d18-9eac-01446df5bf19"
      },
      "source": [
        "int(moving_average(saintx_data2[\"Red Drunk\"], 2)[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsPZpy7MBuiJ",
        "outputId": "91f3b182-0bdd-4f38-9807-d8c0e0f4ea79"
      },
      "source": [
        "int(moving_average(saintx_data2[\"Tripel Drunk\"], 5)[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}